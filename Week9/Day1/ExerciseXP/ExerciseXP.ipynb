{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff25b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestIndPower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552902b2",
   "metadata": {},
   "source": [
    "## Exercise 1: Calculating Required Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73301a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters \n",
    "effect_size = 0.3\n",
    "alpha = 0.05\n",
    "power = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d6724c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 175.38\n"
     ]
    }
   ],
   "source": [
    "# calculate sample size required to detect 3% increase\n",
    "analysis = TTestIndPower()\n",
    "sample_size = analysis.solve_power(effect_size=effect_size,alpha=alpha,power=power)\n",
    "print(f\"Required sample size: {sample_size:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08884b67",
   "metadata": {},
   "source": [
    "#### Conclusion: The sample set of 176 is needed to ensure our test is properly powered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12cc0b",
   "metadata": {},
   "source": [
    "## Exercise 2: Understanding the Relationship Between Effect Size and Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b91704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 393.41\n"
     ]
    }
   ],
   "source": [
    "#1. Conditions: effect_size = 0.2, alpha = 0.05, power = 0.8\n",
    "effect_size = 0.2\n",
    "alpha = 0.05\n",
    "power = 0.8\n",
    "analysis2 = TTestIndPower()\n",
    "sample_size2 = analysis.solve_power(effect_size=effect_size,alpha=alpha,power=power)\n",
    "print(f\"Required sample size: {sample_size2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91766351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 99.08\n"
     ]
    }
   ],
   "source": [
    "#2.  Conditions: effect_size = 0.4, alpha = 0.05, power = 0.8\n",
    "effect_size = 0.4\n",
    "alpha = 0.05\n",
    "power = 0.8\n",
    "analysis2 = TTestIndPower()\n",
    "sample_size2 = analysis.solve_power(effect_size=effect_size,alpha=alpha,power=power)\n",
    "print(f\"Required sample size: {sample_size2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d6b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 63.77\n"
     ]
    }
   ],
   "source": [
    "# 3. Conditions: effect_size = 0.5, alpha = 0.05, power = 0.8\n",
    "effect_size = 0.5\n",
    "alpha = 0.05\n",
    "power = 0.8\n",
    "analysis2 = TTestIndPower()\n",
    "sample_size2 = analysis.solve_power(effect_size=effect_size,alpha=alpha,power=power)\n",
    "print(f\"Required sample size: {sample_size2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a9a62",
   "metadata": {},
   "source": [
    "Conclusion: With an increase in effect size a smaller sample size is required. It is easier to detect a big change (bigger effect size) therefore smaller sample size. is needed.\n",
    "- effect size (0.2) -> 394\n",
    "- effect size (0.4) -> 100\n",
    "- effect size (0.5) -> 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccccd44",
   "metadata": {},
   "source": [
    "## Exercise 3: Exploring the Impact of Statistical Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f8d2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 309.56\n"
     ]
    }
   ],
   "source": [
    "#1. Conditions: effect_size = 0.2, alpha = 0.05, power = 0.7\n",
    "effect_size = 0.2\n",
    "alpha = 0.05\n",
    "power = 0.7\n",
    "analysis2 = TTestIndPower()\n",
    "sample_size2 = analysis.solve_power(effect_size=effect_size,alpha=alpha,power=power)\n",
    "print(f\"Required sample size: {sample_size2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6fd829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 393.41\n"
     ]
    }
   ],
   "source": [
    "#2. Conditions: effect_size = 0.2, alpha = 0.05, power = 0.8\n",
    "effect_size = 0.2\n",
    "alpha = 0.05\n",
    "power = 0.8\n",
    "analysis2 = TTestIndPower()\n",
    "sample_size2 = analysis.solve_power(effect_size=effect_size,alpha=alpha,power=power)\n",
    "print(f\"Required sample size: {sample_size2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "689e5d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 526.33\n"
     ]
    }
   ],
   "source": [
    "#3. Conditions: effect_size = 0.2, alpha = 0.05, power = 0.9\n",
    "effect_size = 0.2\n",
    "alpha = 0.05\n",
    "power = 0.9\n",
    "analysis2 = TTestIndPower()\n",
    "sample_size2 = analysis.solve_power(effect_size=effect_size,alpha=alpha,power=power)\n",
    "print(f\"Required sample size: {sample_size2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea95f0",
   "metadata": {},
   "source": [
    "Conclusion: With an increase in statistical power the sample size required increases as well. It is important while designing A/B testing because higher power ensures we are more likely to detect a true differece between two versions if one ectually exists.  \n",
    "- power (0.7) -> 310\n",
    "- power (0.8) -> 394\n",
    "- power (0.9) -> 527"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884168f",
   "metadata": {},
   "source": [
    "## Exercise 4: Implementing Sequential Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5441f0",
   "metadata": {},
   "source": [
    "1. The stopping criteria for sequential testing:p < 0.02. Check results once per week for four weeks. We will stop if p<0.02.\n",
    "2. The test would run for four weeks and we would calculate  p value that compares A vs B. Once we meet the criteria (p<0.02) the test will stop  and determine a winner, otherwise keep running until the end. At the end of the week 4 if it never stopped we will make a final decision using p<0.05.\n",
    "3. If at the end of week 3 Version B has p-value = 0.02 (right at the limit) we would conclude that version B is very likely better. We need to make sure that we have enough data and results make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa7233",
   "metadata": {},
   "source": [
    "## Exercise 5: Applying Bayesian A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0685123",
   "metadata": {},
   "source": [
    "I would assume that a new feature has 50% chance of improving user engagement (it might imrove but I am not sure).If after collecting data there is a 65% chance I now believe that it's more likely that the new feature helps but i am not completely sure yet. Therefore, I need to continue testing for longer time. If later the probability goes up until 90% we can be sure to release this feature.\n",
    "If posterior probability was only 55% it would mean that this feture doesn't change much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e27b8",
   "metadata": {},
   "source": [
    "## Exercise 6: Implementing Adaptive Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847bfd1",
   "metadata": {},
   "source": [
    "After the first week I would allocate 60% of traffic to layout C  and 20% each to layout A and layout B. In the next weeks I would check results again. If C is doing great I would give it even more traffic (70-80%). If another layout starts doing better, I would adjust my traffic accordingly. After a few weeks if one layout keeps winning, i would use it for everyone.\n",
    "- Challenges: \n",
    "1) Stop testing other layouts too soon -> need to keep at least 10% of users on each version\n",
    "2) Results keep changing -> wait for 2-3 weeks for stable results\n",
    "3) Wrong conclusions -> once the winner is decided, needs to run final A/B testing to confirm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
